# Lesson 10: SIEM Analytics & Threat Correlation Tutorial
## From Raw Data to Security Intelligence

---

## ğŸ¯ Executive Summary

### For Non-Technical Executives

**What Problem Are We Solving?**
Imagine your company has hundreds of security cameras (systems) recording everything that happens. Without analytics, your security team would have to watch all camera feeds simultaneously - an impossible task. SIEM analytics is like having a smart security system that automatically flags suspicious behavior and connects related events to detect complex threats.

**The Business Value:**
- **Early Threat Detection**: Spot attacks before they cause damage
- **Reduced Risk**: Proactively identify security gaps
- **Compliance**: Demonstrate security controls to auditors
- **Efficiency**: Automate security monitoring, reducing manual effort

**Simple Analogy:**
Think of SIEM analytics as a **smart home security system**:
- Individual sensors (door, window, motion) = Individual security logs
- Correlation engine = The brain that connects "door opened + motion detected + alarm disabled"
- Alerts = The system calling you saying "suspicious activity detected"
- Your Lesson 10 system = A working prototype of this smart security

---

## ğŸ—ï¸ Technical Deep Dive

### For Cloud Security Architects

### Core Concepts Explained

#### 1. SIEM Analytics
**What it is**: The process of applying mathematical models and algorithms to security data to identify patterns, anomalies, and potential threats.

**Technical Implementation**:
```bash
# Our Lesson 10 Implementation:
./compute_metrics.sh decision_logs.jsonl
# Output: {"window": 50, "allow": 20, "deny": 30, "deny_ratio": 0.600}
Why it matters:

Baseline Establishment: Understand normal behavior patterns

Anomaly Detection: Identify deviations from established baselines

Trend Analysis: Spot emerging threats through pattern recognition

Risk Quantification: Assign numerical risk scores to activities

2. Threat Correlation
What it is: The process of connecting related security events across multiple systems and timeframes to identify complex attack patterns.

Technical Implementation:

bash
# Our correlation rule in alerts.sh:
THRESHOLD=0.60  # Alert if deny ratio > 60%
# This correlates multiple denied access attempts into a single threat indicator
Why it matters:

Attack Chain Identification: Connect reconnaissance, intrusion, and exfiltration attempts

Multi-Vector Detection: Spot attacks spanning users, systems, and time

Context Enrichment: Add meaning to isolated security events

False Positive Reduction: Separate real threats from noise

Architecture Overview
flowchart TD
    A[ğŸ“± User Access Requests] --> B[ğŸ›¡ï¸ OPA Policy Engine]
    B --> C[ğŸ“Š Decision Events]
    C --> D[ğŸ”„ Event Collector]
    D --> E[ğŸ“ˆ Analytics Engine]
    E --> F{Deny Ratio > 60%?}
    F -->|Yes| G[ğŸš¨ Alert Triggered]
    F -->|No| H[âœ… Normal Operation]
    G --> I[ğŸ“‹ Security Investigation]
    I --> J[âš¡ Automated Response]
    
    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style G fill:#ffebee
    style J fill:#e8f5e8
ğŸ”„ The SIEM Analytics Workflow
Step 1: Data Collection & Normalization
What Happens: Gather security events from across your environment

Our Implementation:

bash
# generate_events.sh collects from OPA policy decisions
# Output: JSONL format with standardized fields
{"ts":"2025-10-07T12:00:00-07:00","user":"ola","risk":25,"result":true}
Enterprise Equivalent:

Firewall logs

Cloud trail logs

Authentication systems

Application logs

Step 2: Analysis & Correlation
What Happens: Apply rules and algorithms to detect threats

Our Implementation:

bash
# compute_metrics.sh analyzes:
# - Rolling windows of events
# - Deny ratios
# - Per-user patterns
# - Statistical anomalies
Advanced Techniques:

UEBA (User Entity Behavior Analytics): Baseline normal user behavior

Machine Learning: Detect novel attack patterns

Threat Intelligence: Cross-reference with known bad actors

Step 3: Alerting & Prioritization
What Happens: Generate and rank security alerts

Our Implementation:

bash
# alerts.sh triggers when:
deny_ratio > THRESHOLD  # 60% in our case
# Output: ğŸš¨ ALERT: Global deny_ratio 0.800 > 0.60
Enterprise Features:

Alert Fatigue Management: Only show high-priority alerts

Risk-Based Prioritization: Focus on critical assets

Automated Triage: Pre-investigate alerts before human review

Step 4: Investigation & Response
What Happens: Analyze and respond to security incidents

Our Implementation:

bash
# Manual investigation using:
./compute_metrics.sh  # Get current state
cat decision_logs.jsonl | jq .  # Examine raw events
Enterprise Capabilities:

Forensic Timeline: Reconstruct attack sequences

SOAR Integration: Automated containment actions

Incident Management: Track investigation progress

End-to-End Analytics Pipeline
flowchart LR
    subgraph A [Phase 1: Data Collection]
        A1[ğŸ” Log Sources] --> A2[ğŸ”„ Normalization]
    end
    
    subgraph B [Phase 2: Analysis]
        B1[ğŸ“Š Metrics Computation] --> B2[ğŸ¯ Pattern Detection]
        B2 --> B3[ğŸ”— Threat Correlation]
    end
    
    subgraph C [Phase 3: Alerting]
        C1[âš ï¸ Alert Generation] --> C2[ğŸšï¸ Prioritization]
    end
    
    subgraph D [Phase 4: Response]
        D1[ğŸ” Investigation] --> D2[âš¡ Containment]
    end
    
    A --> B --> C --> D
    
    style A fill:#f3e5f5
    style B fill:#e8f5e8
    style C fill:#fff3e0
    style D fill:#ffebee
ğŸª Real-World Attack Scenario
Detecting a Brute Force Attack
Normal Behavior (No Alert)
text
Events: 50 login attempts, 25 allowed, 25 denied
Metrics: deny_ratio = 0.500 (50%)
Result: âœ… Normal traffic pattern
Attack Behavior (Alert Triggered)
text
Events: 50 login attempts, 10 allowed, 40 denied  
Metrics: deny_ratio = 0.800 (80%)
Correlation: High denial rate + Multiple users + Short timeframe
Result: ğŸš¨ BRUTE FORCE ATTACK DETECTED
Investigation Steps:
Identify Pattern: High deny ratio across multiple users

Correlate Sources: Check firewall, authentication, and network logs

Contextualize: Cross-reference with threat intelligence

Respond: Block attacking IP ranges, require MFA

Brute Force Attack Detection Flow
sequenceDiagram
    participant U as Attacker
    participant A as Auth System
    participant S as SIEM Analytics
    participant T as SOC Team
    
    Note over U,A: Attack Phase: Reconnaissance
    U->>A: Failed Login (User1)
    U->>A: Failed Login (User2)
    U->>A: Failed Login (User3)
    
    Note over A,S: Detection Phase: Analytics
    A->>S: Send Auth Events
    S->>S: Compute Deny Ratio
    Note right of S: deny_ratio = 80%<br/>Threshold = 60%
    
    Note over S,T: Alert Phase: Correlation
    S->>T: ğŸš¨ HIGH PRIORITY ALERT<br/>Potential Brute Force Attack
    
    Note over T,A: Response Phase: Containment
    T->>A: Block Attacker IP
    T->>A: Require MFA for affected users
    
    Note over U: Attack Blocked ğŸ›¡ï¸
ğŸ› ï¸ Technical Implementation Guide
Architecture Overview
text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚    â”‚  Analytics       â”‚    â”‚   Response      â”‚
â”‚   â€¢ OPA Decisionsâ”‚â”€â”€â”€â–¶â”‚  Engine          â”‚â”€â”€â”€â–¶â”‚   System        â”‚
â”‚   â€¢ Cloud Logs   â”‚    â”‚  â€¢ Metrics       â”‚    â”‚   â€¢ Alerts      â”‚
â”‚   â€¢ Auth Systems â”‚    â”‚  â€¢ Correlation   â”‚    â”‚   â€¢ Automation  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Key Configuration Points
1. Threshold Tuning
bash
# Balance detection vs. false positives
THRESHOLD=0.60  # Current - good for demo
# THRESHOLD=0.70  # Production - fewer false positives
# THRESHOLD=0.50  # Sensitive - more alerts
2. Window Sizing
bash
WINDOW=50    # Current - responsive to changes
# WINDOW=200   # Production - stable, less noisy
# WINDOW=20    # Sensitive - very responsive
3. Multi-Dimensional Correlation
bash
# Enhance with additional factors:
# - Geographic anomalies
# - Time-of-day patterns  
# - Device compliance status
# - User role deviations
ğŸ“Š Metrics That Matter
Security KPIs to Monitor
1. Detection Effectiveness
Mean Time to Detect (MTTD): How quickly threats are identified

False Positive Rate: Percentage of incorrect alerts

Detection Coverage: Percentage of attack types detected

2. Operational Efficiency
Alerts per Analyst: Workload measurement

Automation Rate: Percentage of automated responses

Investigation Time: Time to resolve incidents

3. Risk Management
Threat Exposure: Number of active threats

Compliance Status: Adherence to security frameworks

Control Effectiveness: Performance of security controls

ğŸš€ Production Readiness Checklist
For Enterprise Deployment
âœ… Data Collection
Multiple log sources integrated

Real-time ingestion pipeline

Data normalization and enrichment

Retention policies configured

âœ… Analytics Engine
Machine learning models trained

Correlation rules defined and tested

Baseline behavior established

Anomaly detection calibrated

âœ… Alerting & Response
Alert thresholds optimized

Escalation procedures defined

Automated response playbooks

Integration with SOAR platform

âœ… Operational Excellence
24/7 monitoring coverage

Analyst training completed

Regular rule tuning scheduled

Performance metrics tracked

Enterprise Deployment Architecture
graph TB
    subgraph DataSources [Data Sources Layer]
        DS1[ğŸŒ Cloud Logs]
        DS2[ğŸ–¥ï¸ Endpoint Logs]
        DS3[ğŸ” Auth Systems]
        DS4[ğŸ›¡ï¸ Network Devices]
    end
    
    subgraph Ingestion [Ingestion Layer]
        I1[ğŸ“¥ Log Collector]
        I2[ğŸ”§ Normalization Engine]
        I3[ğŸ’¾ Data Lake]
    end
    
    subgraph Analytics [Analytics Layer]
        A1[ğŸ“Š Real-time Processing]
        A2[ğŸ¤– ML Anomaly Detection]
        A3[ğŸ”— Correlation Engine]
        A4[ğŸ“ˆ Behavioral Analytics]
    end
    
    subgraph Response [Response Layer]
        R1[ğŸš¨ Alert Management]
        R2[âš¡ SOAR Automation]
        R3[ğŸ“‹ Case Management]
        R4[ğŸ“Š Dashboards]
    end
    
    DataSources --> Ingestion
    Ingestion --> Analytics
    Analytics --> Response
    
    style DataSources fill:#e3f2fd
    style Ingestion fill:#f3e5f5
    style Analytics fill:#e8f5e8
    style Response fill:#fff3e0
ğŸ’¡ Best Practices
For Cloud Security Architects
1. Start Small, Scale Smart
Begin with critical data sources

Focus on high-impact use cases

Gradually expand coverage

Continuously tune and optimize

2. Balance Detection vs. Noise
Set realistic thresholds

Implement alert fatigue controls

Use risk-based prioritization

Regularly review false positives

3. Embrace Automation
Automate repetitive investigations

Implement automated containment

Use machine learning where possible

Continuously improve playbooks

4. Foster Collaboration
Involve stakeholders early

Share insights across teams

Integrate with IT operations

Partner with business units

Continuous Improvement Cycle
flowchart TD
    A[ğŸ¯ Define Use Cases] --> B[ğŸ› ï¸ Implement Rules]
    B --> C[ğŸ“Š Monitor Performance]
    C --> D{Effective Detection?}
    D -->|Yes| E[âœ… Maintain & Scale]
    D -->|No| F[ğŸ”§ Tune Rules]
    F --> G[ğŸ”„ Update Baselines]
    G --> C
    
    H[ğŸ“ˆ Metrics Tracking] -.-> C
    I[ğŸ“ Team Training] -.-> B
    J[ğŸ”„ Threat Intel] -.-> F
    
    style A fill:#e3f2fd
    style E fill:#e8f5e8
    style F fill:#fff3e0
Multi-Stage Attack Correlation
timeline
    title Advanced Threat Detection Timeline
    section Reconnaissance Phase
        T-5m : Port Scanning<br/>Detected via Network Logs
        T-3m : Failed Logins<br/>Multiple User Accounts
    section Intrusion Phase  
        T-1m : Successful Login<br/>Compromised Credentials
        T-30s : Privilege Escalation<br/>Admin Rights Obtained
    section Exfiltration Phase
        T+0s : Data Access<br/>Sensitive Files Accessed
        T+2m : Data Transfer<br/>Large Outbound Traffic
    section Detection & Response
        T+3m : ğŸš¨ CORRELATION ALERT<br/>Multi-stage Attack Pattern
        T+4m : âš¡ AUTOMATED RESPONSE<br/>Account Disabled, IP Blocked
ğŸ¯ Conclusion
Executive Takeaway
SIEM analytics transforms your security from reactive to proactive. Instead of waiting for damage to occur, you can detect and stop threats early. Our Lesson 10 implementation demonstrates the core principles that scale to enterprise-level security operations.

Architect Insight
The patterns implemented in Lesson 10 - event collection, metric computation, threshold alerting, and correlation - form the foundation of modern security operations. These concepts directly translate to production SIEM platforms like Splunk, Azure Sentinel, and Google Chronicle.

Next Steps
Extend Data Sources: Add cloud logs, network data, endpoint telemetry

Enhance Analytics: Implement machine learning and UEBA

Automate Response: Integrate with SOAR platforms

Scale Architecture: Move to distributed processing

ğŸ“š Additional Resources
NIST SP 800-137: Information Security Continuous Monitoring

SANS SIEM Essentials

Cloud Security Alliance SIEM Guidance

Lab Status: âœ… Production-Ready Patterns Implemented
Last Updated: October 2024
Technical Level: Intermediate to Advanced
Business Impact: High - Proactive Threat Detection

text

## Step 3: Save and exit nano
- **Ctrl+O** â†’ **Enter** â†’ **Ctrl+X**

## Step 4: Create the separate Mermaid source file

```bash
nano siem-analytics-diagrams.mmd
Copy and paste this Mermaid source content:

%% SIEM Analytics Architecture Diagram
flowchart TD
    A[ğŸ“± User Access Requests] --> B[ğŸ›¡ï¸ OPA Policy Engine]
    B --> C[ğŸ“Š Decision Events]
    C --> D[ğŸ”„ Event Collector]
    D --> E[ğŸ“ˆ Analytics Engine]
    E --> F{Deny Ratio > 60%?}
    F -->|Yes| G[ğŸš¨ Alert Triggered]
    F -->|No| H[âœ… Normal Operation]
    G --> I[ğŸ“‹ Security Investigation]
    I --> J[âš¡ Automated Response]
    
    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style G fill:#ffebee
    style J fill:#e8f5e8

%% SIEM Analytics Workflow
flowchart LR
    subgraph A [Phase 1: Data Collection]
        A1[ğŸ” Log Sources] --> A2[ğŸ”„ Normalization]
    end
    
    subgraph B [Phase 2: Analysis]
        B1[ğŸ“Š Metrics Computation] --> B2[ğŸ¯ Pattern Detection]
        B2 --> B3[ğŸ”— Threat Correlation]
    end
    
    subgraph C [Phase 3: Alerting]
        C1[âš ï¸ Alert Generation] --> C2[ğŸšï¸ Prioritization]
    end
    
    subgraph D [Phase 4: Response]
        D1[ğŸ” Investigation] --> D2[âš¡ Containment]
    end
    
    A --> B --> C --> D
    
    style A fill:#f3e5f5
    style B fill:#e8f5e8
    style C fill:#fff3e0
    style D fill:#ffebee

%% Attack Detection Sequence
sequenceDiagram
    participant U as Attacker
    participant A as Auth System
    participant S as SIEM Analytics
    participant T as SOC Team
    
    Note over U,A: Attack Phase: Reconnaissance
    U->>A: Failed Login (User1)
    U->>A: Failed Login (User2)
    U->>A: Failed Login (User3)
    
    Note over A,S: Detection Phase: Analytics
    A->>S: Send Auth Events
    S->>S: Compute Deny Ratio
    Note right of S: deny_ratio = 80%<br/>Threshold = 60%
    
    Note over S,T: Alert Phase: Correlation
    S->>T: ğŸš¨ HIGH PRIORITY ALERT<br/>Potential Brute Force Attack
    
    Note over T,A: Response Phase: Containment
    T->>A: Block Attacker IP
    T->>A: Require MFA for affected users
    
    Note over U: Attack Blocked ğŸ›¡ï¸

%% Enterprise Architecture
graph TB
    subgraph DataSources [Data Sources Layer]
        DS1[ğŸŒ Cloud Logs]
        DS2[ğŸ–¥ï¸ Endpoint Logs]
        DS3[ğŸ” Auth Systems]
        DS4[ğŸ›¡ï¸ Network Devices]
    end
    
    subgraph Ingestion [Ingestion Layer]
        I1[ğŸ“¥ Log Collector]
        I2[ğŸ”§ Normalization Engine]
        I3[ğŸ’¾ Data Lake]
    end
    
    subgraph Analytics [Analytics Layer]
        A1[ğŸ“Š Real-time Processing]
        A2[ğŸ¤– ML Anomaly Detection]
        A3[ğŸ”— Correlation Engine]
        A4[ğŸ“ˆ Behavioral Analytics]
    end
    
    subgraph Response [Response Layer]
        R1[ğŸš¨ Alert Management]
        R2[âš¡ SOAR Automation]
        R3[ğŸ“‹ Case Management]
        R4[ğŸ“Š Dashboards]
    end
    
    DataSources --> Ingestion
    Ingestion --> Analytics
    Analytics --> Response
    
    style DataSources fill:#e3f2fd
    style Ingestion fill:#f3e5f5
    style Analytics fill:#e8f5e8
    style Response fill:#fff3e0

%% Continuous Improvement Cycle
flowchart TD
    A[ğŸ¯ Define Use Cases] --> B[ğŸ› ï¸ Implement Rules]
    B --> C[ğŸ“Š Monitor Performance]
    C --> D{Effective Detection?}
    D -->|Yes| E[âœ… Maintain & Scale]
    D -->|No| F[ğŸ”§ Tune Rules]
    F --> G[ğŸ”„ Update Baselines]
    G --> C
    
    H[ğŸ“ˆ Metrics Tracking] -.-> C
    I[ğŸ“ Team Training] -.-> B
    J[ğŸ”„ Threat Intel] -.-> F
    
    style A fill:#e3f2fd
    style E fill:#e8f5e8
    style F fill:#fff3e0

%% Multi-Stage Attack Timeline
timeline
    title Advanced Threat Detection Timeline
    section Reconnaissance Phase
        T-5m : Port Scanning<br/>Detected via Network Logs
        T-3m : Failed Logins<br/>Multiple User Accounts
    section Intrusion Phase  
        T-1m : Successful Login<br/>Compromised Credentials
        T-30s : Privilege Escalation<br/>Admin Rights Obtained
    section Exfiltration Phase
        T+0s : Data Access<br/>Sensitive Files Accessed
        T+2m : Data Transfer<br/>Large Outbound Traffic
    section Detection & Response
        T+3m : ğŸš¨ CORRELATION ALERT<br/>Multi-stage Attack Pattern
        T+4m : âš¡ AUTOMATED RESPONSE<br/>Account Disabled, IP Blocked
Step 5: Save and exit nano
Ctrl+O â†’ Enter â†’ Ctrl+X

Step 6: Now commit and push everything
bash
cd ~/zero-trust-comprehensive-course
git add labs/10-siem-analytics/
git commit -m "feat: complete Lesson 10 with comprehensive tutorial and Mermaid diagrams

- Added complete SIEM analytics tutorial for all audiences
- Included professional Mermaid diagrams for visual learning
- Executive summary for business leadership
- Technical deep dive for security architects
- Real-world attack scenarios and detection workflows
- Production readiness checklist and best practices

Key Features:
ğŸ¯ Dual-audience approach (executives + technical)
ğŸ—ï¸ 6 professional Mermaid diagrams with color coding
ğŸ”„ End-to-end analytics workflow visualization
ğŸª Real attack detection scenarios
ğŸš€ Enterprise deployment guidance
ğŸ’¡ Continuous improvement framework

